{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad82f998-4d96-47d2-99cd-c938ce57a7bc",
   "metadata": {},
   "source": [
    "Батчинг (batch processing) - это техника обработки данных группами (пакетами), а не по одному.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbd5aa0-6360-4177-9cb6-7077b94c448d",
   "metadata": {},
   "source": [
    "При кросс-валидации данные делятся на несколько частей, часть из которых используется обучения, а оставшаяся часть — для проверки. Это позволяет получить надежную оценку, так как для проверки используются данные, которые модель еще не видела."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09cc418-22c0-4ad1-932f-9282b3c8c84e",
   "metadata": {},
   "source": [
    "## Типы кросс-валидации\n",
    "\n",
    "### Валидация на отложенных данных (Hold-Out Cross-Validation)\n",
    "Самый простой способ: данные делят на тренировочные и тестовые. Первые используются для обучения модели, а тестовые — для оценки производительности. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82cc1a2-fa14-4d73-aa21-49d1b63898f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hold-Out Cross-Validation\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "X, y = np.arange(1000).reshape((500, 2)), np.arange(500)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a7fb3-a3ff-4f42-86e7-d113bd3d5109",
   "metadata": {},
   "source": [
    "Если у вас достаточно данных, лучше всегда предусматривать также валидационное множество. Это третье множество данных, которое позволяет безопасно оценить качество модели и предотвратить её переобучение.\n",
    "\n",
    "Разбиение данных на тренировочное, тестовое и валидационное множество в библиотеке sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b07475-f602-4f3e-9be6-e14fcff5e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "X, y = np.arange(1000).reshape((500, 2)), np.arange(500)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.1, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040e9710-6f10-4581-a1f1-c9568a502945",
   "metadata": {},
   "source": [
    "Если вы перебираете какие-то модели для вашей задачи, то оптимизировать их качество стоит на валидационном множестве, а окончательно сравнивать модели на тестовом множестве.\n",
    "\n",
    "Оптимизация модели может включать:\n",
    "\n",
    "- подбор гиперпараметров;\n",
    "- подбор архитектуры (если речь идёт о нейросетях);\n",
    "- подбор оптимального трешхолда для максимизации значений целевой метрики — например, вы делаете двуклассовую классификацию, а модель выдаёт - непрерывные значения от 0 до 1, которые нужно бинаризовать так, чтобы получить максимальный скор по F1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5827404d-1f7c-4aa2-b5a8-311b95b93aca",
   "metadata": {},
   "source": [
    "### k-Fold (K-Fold Cross-Validation)\n",
    "Метод k-Fold чаще всего имеют в виду, когда говорят о кросс-валидации. Он является обобщением метода hold-out и представляет из себя следующий алгоритм:\n",
    "\n",
    "- Фиксируется некоторое целое число k (обычно от 5 до 10), меньше числа семплов в датасете.\n",
    "\n",
    "- Датасет разбивается на k одинаковых частей (в последней части может быть меньше семплов, чем в остальных). Эти части называются фолдами.\n",
    "\n",
    "- Далее происходит k итераций, во время каждой из которых один фолд выступает в роли тестового множества, а объединение остальных — в роли тренировочного. Модель учится на k−1 фолде и тестируется на оставшемся.\n",
    "\n",
    "- Финальный скор модели либо получается усреднением k получившихся тестовых результатов, либо измеряется на отложенном тестовом множестве, не участвовавшем в кросс-валидации.\n",
    "\n",
    "\n",
    "Данные делятся на несколько равных частей (К): одна используется для проверки, остальные — для обучения. Процесс повторяется столько раз, на сколько частей мы поделили данные. Каждый блок должен быть использован как тестовый набор.\n",
    "\n",
    "После окончания обучения результаты тестов приводят к среднему значению. Это позволяет получить более надежную оценку производительности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16479bf-b126-4453-ba77-ec52660b81fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    " \n",
    "X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "kf = KFold(n_splits=2)\n",
    " \n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "'''\n",
    "result:\n",
    "TRAIN: [2 3] TEST: [0 1]\n",
    "TRAIN: [0 1] TEST: [2 3]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a72920-2d4d-42e8-9135-caedbaafebd8",
   "metadata": {},
   "source": [
    "В sklearn есть также метод cross_val_score, который принимает на вход классификатор, данные и способ разбиения данных (либо число фолдов) и возвращает результаты кросс-валидации:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33e822-752e-4ff3-ad8e-db1cbae972b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    " \n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(scores)\n",
    "'''\n",
    "result:\n",
    "array([0.96..., 1. , 0.96..., 0.96..., 1. ])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec180a4-1cde-4c04-bbb0-a1bed4a0c68c",
   "metadata": {},
   "source": [
    "### стратификация\n",
    "стратификация — разбиение на трейн и тест, сохраняющее исходное соотношение классов\n",
    "Стратифицированная K-блочная кросс-валидация (Stratified K-Fold Cross-Validation)\n",
    "Проводится аналогично K-блочной кросс-валидации, но с учетом пропорции классов в каждом блоке. Используется, когда данные имеют несбалансированные классы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d940eb2b-f63c-4205-b2d3-19d692c80ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "X, y = np.arange(1000).reshape((500, 2)), np.random.choice(4, size=500, p=[0.1, 0.2, 0.3, 0.4])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f5054f-702d-4f63-a671-34595ffc6aad",
   "metadata": {},
   "source": [
    "### Leave-one-out\n",
    "Метод leave-one-out (LOO) — частный случай метода k-Fold: в нём каждый фолд состоит ровно из одного семпла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8f533-1637-4dde-8725-647d35467c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    " \n",
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "y = np.array([1, 2, 3])\n",
    "loo = LeaveOneOut()\n",
    " \n",
    "for train_index, test_index in loo.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "'''\n",
    "result:\n",
    "TRAIN: [1 2] TEST: [0]\n",
    "TRAIN: [0 2] TEST: [1]\n",
    "TRAIN: [0 1] TEST: [2]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcaf282-ec27-4005-ad1b-9302276362ee",
   "metadata": {},
   "source": [
    "Метод stratified k-Fold — это метод k-Fold, использующий стратификацию при разбиении на фолды: каждый фолд содержит примерно такое же соотношение классов, как и всё исходное множество. Такой подход может потребоваться в случае, например, очень несбалансированного соотношения классов, когда при обычном случайном разбиении некоторые фолды могут либо вообще не содержать семплов каких-то классов, либо содержать их слишком мало."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811840e8-9b3c-4b25-b5a7-24691b0d0320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    " \n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    " \n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "'''\n",
    "result:\n",
    "TRAIN: [1 3] TEST: [0 2]\n",
    "TRAIN: [0 2] TEST: [1 3]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2c6d8f-ed71-4c58-8f94-cb132b8b13e5",
   "metadata": {},
   "source": [
    "Основные методы кросс-валидации:\n",
    "\n",
    "- Hold-out: простое разделение на тренировочное, тестовое и валидационное подмножества. Критически важно перемешивать данные, чтобы предотвратить зависимость качества обучения от порядка данных. Валидационное множество используется для подбора гиперпараметров, а финальная оценка — на тесте.\n",
    "- k-Fold: датасет делится на k частей, модель обучается и тестируется k раз. Даёт более надёжную оценку, чем hold-out, но требует больше ресурсов. Подходит для небольших данных.\n",
    "- Stratified k-Fold: сохраняет распределение классов в фолдах, важно для несбалансированных данных (например, спам-фильтрация).\n",
    "- Leave-one-out (LOO): частный случай k-Fold, где каждый фолд — один образец. Применяется при очень малом количестве данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d76ab8c-7e9a-4b5c-ab29-6aaf2c4e3582",
   "metadata": {},
   "source": [
    "### MapReduce\n",
    "в основе работы MapReduce лежат Map и Reduce. \n",
    "\n",
    "- Map: Этот шаг преобразует входные данные в набор пар «ключ-значение». Каждая функция Map работает независимо и параллельно с другими, обрабатывая свою часть входной информации. В результате каждого вызова функции Map генерируется набор промежуточных пар «ключ-значение».\n",
    "\n",
    "- Reduce: На этом шаге происходит работа с данными, сгруппированными по ключу, и преобразование их в набор выходных значений. Reduce работает после того, как все функции Map завершили свою работу. Она принимает ключ и множество значений, сопоставленных этому ключу, и выдает набор выходных значений (обычно одно значение для каждого уникального ключа)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05bfb137-9d49-430d-9e59-00423d0e844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Any, Callable\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import multiprocessing\n",
    "\n",
    "class SimpleMapReduce:\n",
    "    def __init__(self, num_workers=None):\n",
    "        self.num_workers = num_workers or multiprocessing.cpu_count()\n",
    "    \n",
    "    def map_reduce(self, \n",
    "                   data: List,\n",
    "                   mapper: Callable,\n",
    "                   reducer: Callable,\n",
    "                   shuffle_sort: bool = True) -> List:\n",
    "        \"\"\"\n",
    "        Основная функция MapReduce\n",
    "        \"\"\"\n",
    "        # 1. Map этап\n",
    "        mapped = self._map(data, mapper)\n",
    "        \n",
    "        # 2. Shuffle этап (группировка по ключам)\n",
    "        shuffled = self._shuffle(mapped, shuffle_sort)\n",
    "        \n",
    "        # 3. Reduce этап\n",
    "        reduced = self._reduce(shuffled, reducer)\n",
    "        \n",
    "        return reduced\n",
    "    \n",
    "    def _map(self, data: List, mapper: Callable) -> List[Tuple]:\n",
    "        \"\"\"Параллельное выполнение Map\"\"\"\n",
    "        with ThreadPoolExecutor(max_workers=self.num_workers) as executor:\n",
    "            results = list(executor.map(mapper, data))\n",
    "        # Преобразуем в плоский список\n",
    "        flat_results = []\n",
    "        for result in results:\n",
    "            flat_results.extend(result)\n",
    "        return flat_results\n",
    "    \n",
    "    def _shuffle(self, mapped_data: List[Tuple], sort: bool) -> dict:\n",
    "        \"\"\"Группировка данных по ключам\"\"\"\n",
    "        shuffled = defaultdict(list)\n",
    "        for key, value in mapped_data:\n",
    "            shuffled[key].append(value)\n",
    "        \n",
    "        if sort:\n",
    "            # Сортировка ключей (опционально)\n",
    "            shuffled = dict(sorted(shuffled.items()))\n",
    "        \n",
    "        return shuffled\n",
    "    \n",
    "    def _reduce(self, shuffled_data: dict, reducer: Callable) -> List:\n",
    "        \"\"\"Параллельное выполнение Reduce\"\"\"\n",
    "        results = []\n",
    "        with ThreadPoolExecutor(max_workers=self.num_workers) as executor:\n",
    "            # Подготавливаем задачи\n",
    "            tasks = [(key, values) for key, values in shuffled_data.items()]\n",
    "            # Выполняем reduce\n",
    "            reduced = executor.map(\n",
    "                lambda task: (task[0], reducer(task[0], task[1])), \n",
    "                tasks\n",
    "            )\n",
    "            results = list(reduced)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e904e12-0fa3-417a-ac21-9e2f0e4b9411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count Results:\n",
      "  обучение: 3\n",
      "  машинное: 2\n",
      "  deep: 1\n",
      "  learning: 1\n",
      "  глубокое: 1\n",
      "  и: 1\n",
      "  машинного: 1\n",
      "  обучения: 1\n",
      "  часть: 1\n"
     ]
    }
   ],
   "source": [
    "# Пример данных\n",
    "documents = [\n",
    "    \"машинное обучение \",\n",
    "    \"глубокое обучение часть машинного обучения\",\n",
    "    \"машинное обучение и deep learning\"\n",
    "]\n",
    "\n",
    "def word_count_mapper(doc: str) -> List[Tuple]:\n",
    "    \"\"\"Map: разбиваем документ на слова\"\"\"\n",
    "    words = doc.lower().split()\n",
    "    return [(word, 1) for word in words]\n",
    "\n",
    "def word_count_reducer(key: str, values: List[int]) -> int:\n",
    "    \"\"\"Reduce: суммируем количества\"\"\"\n",
    "    return sum(values)\n",
    "\n",
    "# Запуск MapReduce\n",
    "mr = SimpleMapReduce()\n",
    "result = mr.map_reduce(\n",
    "    data=documents,\n",
    "    mapper=word_count_mapper,\n",
    "    reducer=word_count_reducer\n",
    ")\n",
    "\n",
    "print(\"Word Count Results:\")\n",
    "for word, count in sorted(result, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f9d186-7466-46d5-8c16-d5b43e625aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, test_index in kf.split(X):\n",
    "X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "model = LogisticRegression)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "# Повторяем то же, что и в k-fold\n",
    "\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "# Сортируем по дате\n",
    "data = data.sort_values(by='date')\n",
    "X = data.drop(['target', 'date'], axis=1)\n",
    "y = data['target']\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "# Повторяем то же, что и в k-fold\n",
    "\n",
    "\n",
    "from sklearn.model _selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "for train_index, test_index in loo.split(X):\n",
    "# Этот метод может быть очень время затратным на больших\n",
    "# Повторяем то же, что и в k-fold\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "# Повторяем то же, что и в k-fold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
